# AdvB-TD3
In this study, we introduce the Advisory Board TD3 (AdvB-TD3) framework, which integrates the Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm with a cooperative advisory board structure to enhance decision-making performance in dynamic and stochastic environments. The AdvB-TD3 framework employs a shared critic network and dynamic member management, enabling robust, adaptive, and scalable decision-making processes. The proposed methodology was rigorously evaluated in MuJoCo environments, including BipedalWalker-v3, HalfCheetah-v4, Humanoid-v4, InvertedPendulum-v4, InvertedDoublePendulum-v4, MountainCarContinuous-v0, Pendulum-v1, and Swimmer-v4. Experimental results demonstrated that AdvB-TD3 consistently outperformed TD3 across diverse tasks, achieving faster convergence, higher cumulative rewards, and reduced performance variability. When compared to other state-of-the-art algorithms, such as Q-Prop, ACER, and Off-Policy TRPO, AdvB-TD3 exhibited superior stability and learning efficiency, particularly in complex environments like BipedalWalker and Humanoid. Moreover, the frameworkâ€™s ability to maintain low variability across trials highlights its reliability in high-dimensional tasks. Overall, AdvB-TD3 establishes a new benchmark for RL methods, outperforming conventional and advanced approaches in continuous control domains. Its innovative architecture and demonstrated superiority across a wide range of scenarios position it as a robust, efficient, and scalable solution for high-dimensional decision-making problems, with significant implications for advancing AI-driven systems.
